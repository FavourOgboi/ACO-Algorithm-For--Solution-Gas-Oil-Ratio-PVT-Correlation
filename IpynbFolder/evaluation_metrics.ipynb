{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation_Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjWGEyY7eQhq",
    "outputId": "85cc08db-696d-4f20-bfd3-328c9a894df0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming 'pvt_Data' is in a directory relative to your current script\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m module_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvt_Data\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Add the module path to the system path\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(module_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Now try importing the module\n",
    "from pvt_data import pvt_data\n",
    "\n",
    "\n",
    "# Now try importing the module\n",
    "from pvt_Data.pvt_data import pvt_data\n",
    "\n",
    "# an empty list to store rows of X\n",
    "X_list = []\n",
    "\n",
    "# Iterate through each dictionary in pvt_data\n",
    "for data in pvt_data:\n",
    "    \n",
    "    # Extracting relevant values and append as a list to X_list\n",
    "    row = [\n",
    "        data['bubble_point_pressure'],\n",
    "        data['api_gravity'],\n",
    "        data['gas_gravity'],\n",
    "        data['reservoir_temperature']\n",
    "    ]\n",
    "    \n",
    "    X_list.append(row)\n",
    "\n",
    "# Convert X_list into a NumPy array\n",
    "X = np.array(X_list)\n",
    "\n",
    "print(\"Input matrix (X):\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GSnpAImee73",
    "outputId": "2732471d-1afa-441b-f9af-883f67d65946"
   },
   "outputs": [],
   "source": [
    "# Initializing an empty list to store y values\n",
    "y_list = []\n",
    "\n",
    "# Iterating through each dictionary in pvt_data to extract 'actual_gor'\n",
    "for data in pvt_data:\n",
    "    y_list.append(data['actual_gor'])\n",
    "\n",
    "# Converting y_list into a NumPy array\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(\"\\nTarget variable (y):\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "G8HNtBHDdedV",
    "outputId": "fa15df1b-3fea-4d2f-e2b9-68bb7119c2cd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(  X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZbdThwOhQJi",
    "outputId": "dfa191b6-5596-4fe5-b3f6-fb9995ebf359"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# Example actual GOR values (y_true) and estimated GOR values (estimated_gor)\n",
    "y_true = np.array([737, 684, 620, 555, 492, 429, 365, 301, 235, 155])\n",
    "estimated_gor = np.array([739.00506346, 685.75514367, 620.8162171, 555.87729053, 490.93836396, 425.99943739, 361.06051082, 296.12158426, 231.18265769, 166.24373112])\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_true, estimated_gor)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_true, estimated_gor)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate Correlation Coefficient\n",
    "correlation_coefficient, _ = pearsonr(y_true, estimated_gor)\n",
    "\n",
    "# Calculate Average Percent Relative Error (%)\n",
    "percent_relative_errors = np.abs((y_true - estimated_gor) / y_true) * 100\n",
    "average_percent_relative_error = np.mean(percent_relative_errors)\n",
    "\n",
    "# Calculate Sum of Squared Residuals\n",
    "squared_residuals = (y_true - estimated_gor) ** 2\n",
    "sum_squared_residuals = np.sum(squared_residuals)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Correlation Coefficient: {correlation_coefficient}\")\n",
    "print(f\"Average Percent Relative Error (%): {average_percent_relative_error}\")\n",
    "print(f\"Sum of Squared Residuals: {sum_squared_residuals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEDpvZ89hQy8"
   },
   "source": [
    "Mean Absolute Error (MAE): There is an average absolute difference of 3.34 between the estimated and actual values of GOR. This indicates that our forecasts are generally off by roughly 3.34 GOR units.\r\n",
    "\r\n",
    "Mean Squared Error (MSE): There is an average squared discrepancy of 19.90 between the estimated and real GOR values. Compared to MAE, MSE assigns greater weight to larger errors.\r\n",
    "\r\n",
    "Root Mean Squared Error (RMSE): RMSE is around 4.46, which is the square root of MSE. Similar to GOR, it offers a measurement of the error spread in the same units. According to RMSE, there is an average deviation of 4.46 units of GOR between our projections and actual val\n",
    "\n",
    "Correlation Coefficient: The estimated and real GOR values have a very strong linear relationship, as seen by the high correlation coefficient of roughly 0.9997. This implies that the predictions made by our model closely match the observed data.\r\n",
    "\r\n",
    "Average Percentage Relative Error (%): At around 1.33%, the average percentage relative error is calculated. This statistic demonstrates that our projections generally differ by 1.33% in either direction from the actual GOR values.\r\n",
    "\r\n",
    "Sum of Squared Residuals: The entire error between our anticipated and real GOR values is measured by the sum of squared residuals, which is roughly 198.98. Better model performance is indicated by lower values.\r\n",
    "ues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svPnzYvtlZW4"
   },
   "source": [
    "### Cross Plot of Estimated vs Actual Gas Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "I44C_NuVlZcl",
    "outputId": "b5aa9412-4836-4bd6-8a6f-36f4604cb710"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants for gas solubility calculation (replace with actual values)\n",
    "gas_gravity = 0.743  # Specific gravity of gas\n",
    "api_gravity = 37     # API gravity of oil\n",
    "reservoir_pressure = 2000  # Example reservoir pressure in psi\n",
    "\n",
    "# Calculate estimated gas solubility\n",
    "def calculate_gas_solubility(gor):\n",
    "    return (gor * gas_gravity) / (api_gravity * reservoir_pressure)\n",
    "\n",
    "# Calculate actual gas solubility from PVT data\n",
    "actual_gas_solubility = []\n",
    "for data in pvt_data:\n",
    "    actual_gor = data['actual_gor']\n",
    "    actual_gas_solubility.append(calculate_gas_solubility(actual_gor))\n",
    "\n",
    "# Calculate estimated gas solubility from estimated GOR\n",
    "estimated_gas_solubility = []\n",
    "for gor in estimated_gor:\n",
    "    estimated_gas_solubility.append(calculate_gas_solubility(gor))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(actual_gas_solubility, estimated_gas_solubility, color='blue', label='Estimated vs Actual Gas Solubility')\n",
    "plt.plot([min(actual_gas_solubility), max(actual_gas_solubility)], [min(actual_gas_solubility), max(actual_gas_solubility)], color='red', linestyle='--', label='Ideal Fit')\n",
    "plt.xlabel('Actual Gas Solubility')\n",
    "plt.ylabel('Estimated Gas Solubility')\n",
    "plt.title('Cross Plot of Estimated vs Actual Gas Solubility')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accurate Predictions**: The closely fitting red dashed line shows that our estimated gas solubility values match the actual values very well.\n",
    "\n",
    "**Strong Relationship**: The scatter plot's straight line suggests a clear connection between our estimated and actual gas solubility values. This means our method of predicting gas solubility using factors like GOR and pressure works effectively.\n",
    "\n",
    "**Model Confirmation**: The plot confirms that our method for estimating gas solubility is reliable. Most points fall close to the ideal line, showing that our predictions are consistent and accurate under specific reservoir conditions.\n",
    "\n",
    "**Performance Check**: By looking at how close the points are to the ideal line, we can see how well our model performs. A tight cluster around the line means our predictions are consistent, while larger differences might show where we can improve our model.\n",
    "\n",
    "**Real-world Use**: This confirmation supports using our model in real-world situations where knowing gas solubility accurately is important, like in managing reservoirs or planning gas extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute error against Bubble Point Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute error\n",
    "absolute_error = [abs(estimated - actual) for estimated, actual in zip(estimated_gor, bubble_point_pressure)]\n",
    "\n",
    "# Error plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(bubble_point_pressure, absolute_error, marker='o', linestyle='-', color='green', label='Absolute Error')\n",
    "plt.title('Absolute Error Plot')\n",
    "plt.xlabel('Bubble Point Pressure')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that the **absolute error decreases as the Bubble Point Pressure (BPP) increases**.\n",
    "\n",
    "High Error at Low BPP: When BPP is between 0 and 200, the absolute error is relatively high, above 10.\n",
    "Moderate Error at Intermediate BPP: As BPP increases from 200 to 500, the absolute error fluctuates but generally trends downward, moving from around 4 to between 2 and 6.\n",
    "Low Error at High BPP: When BPP is between 500 and 700, the absolute error stabilizes at a low range of 0 to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = []\n",
    "for estimated, actual in zip(estimated_gor, bubble_point_pressure):\n",
    "    residual = estimated - actual\n",
    "    residuals.append(residual)\n",
    "\n",
    "# Print residuals\n",
    "print(\"Residuals:\")\n",
    "for i, (bubble_pressure, residual) in enumerate(zip(bubble_point_pressure, residuals), start=1):\n",
    "    print(f\"Point {i}: Bubble Point Pressure = {bubble_pressure}, Residual = {residual}\")\n",
    "\n",
    "# Residual plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(bubble_point_pressure, residuals, color='purple', label='Residuals')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "plt.title('Residual Plot')\n",
    "plt.xlabel('Bubble Point Pressure')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perfect prediction line, when the estimated values exactly match the actual values, is represented by the horizontal line at zero in the residual plot. The model overestimated the real values, as indicated by the points above this line, and underestimated the actual values, as indicated by the points below it..\r\n",
    "ine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals' distribution around the zero line provides insight into the correctness of the model:\n",
    "\n",
    "**Symmetrical Distribution:** The model may not consistently exhibit a bias toward overestimating or underestimating the values if the residuals are distributed symmetrically around the zero line.\n",
    "\n",
    "**Random Scatter:** The model's errors are random when the residuals are scattered and do not exhibit any discernible pattern, indicating a decent fit. Relative to the data, patterns in the residuals may suggest that the model is lacking some important information or trends.\n",
    "\n",
    "**Size of Residuals:** Greater residuals show areas where the model's predictions substantially differ from actual values, whereas smaller residuals show more accurate forecasts.\n",
    "\n",
    "\n",
    "Although there are occasional deviations, particularly at the extremities of the data range, the majority of residuals in this instance are close to zero, suggesting that the model's predictions are generally accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error Across BPP Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given data\n",
    "absolute_error = [\n",
    "    2.005063459999974, 1.7551436700000522, 0.8162171000000171, \n",
    "    0.877290529999982, 1.0616360399999962, 3.0005626099999745, \n",
    "    3.9394891800000096, 4.87841573999998, 3.8173423099999866, \n",
    "    11.243731120000007\n",
    "]\n",
    "bubble_point_pressure = [737, 684, 620, 555, 492, 429, 365, 301, 235, 155]\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'absolute_error': absolute_error,\n",
    "    'bubble_point_pressure': bubble_point_pressure\n",
    "})\n",
    "\n",
    "# Define bins for BPP categories\n",
    "bins = [0, 300, 500, 700, 800]  # Adjust bins as per your specific data range\n",
    "\n",
    "# Categorize BPP into bins\n",
    "data['bpp_category'] = pd.cut(data['bubble_point_pressure'], bins=bins, labels=['Low BPP', 'Medium BPP', 'High BPP', 'Very High BPP'])\n",
    "\n",
    "# Calculate mean absolute error for each BPP category\n",
    "absolute_errors_by_category = data.groupby('bpp_category')['absolute_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_errors_by_category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_errors_by_category.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(absolute_errors_by_category.index, absolute_errors_by_category.values, color='skyblue')\n",
    "plt.title('Mean Absolute Error Across BPP Categories')\n",
    "plt.xlabel('BPP Categories')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest mean absolute error occurs in the Low BPP category, followed by Medium BPP, Very High BPP, and High BPP."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
